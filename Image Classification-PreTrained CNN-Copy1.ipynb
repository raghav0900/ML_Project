{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b232ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a656eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20920d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_ids.txt', 'r') as file:\n",
    "    # Read all lines into a list\n",
    "    lines = file.readlines()\n",
    "    test_ids = []\n",
    "\n",
    "    # Print each line\n",
    "    for line in lines:\n",
    "        test_ids.append(line.strip() + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bac303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_ids.txt', 'r') as file:\n",
    "    # Read all lines into a list\n",
    "    lines = file.readlines()\n",
    "    train_ids = []\n",
    "\n",
    "    # Print each line\n",
    "    for line in lines:\n",
    "        train_ids.append(line.strip() + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61a2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_ids.txt', 'r') as file:\n",
    "    # Read all lines into a list\n",
    "    lines = file.readlines()\n",
    "    val_ids = []\n",
    "\n",
    "    # Print each line\n",
    "    for line in lines:\n",
    "        val_ids.append(line.strip() + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29335bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training dataset:  134823\n",
      "Number of images in validation dataset:  5000\n",
      "Number of images in testing dataset:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in training dataset: \", len(train_ids))\n",
    "print(\"Number of images in validation dataset: \", len(val_ids))\n",
    "print(\"Number of images in testing dataset: \", len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ff78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image files\n",
    "def get_image_files(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    image_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if file.lower().endswith('.jpg'):\n",
    "            image_files.append(file)\n",
    "    \n",
    "    return image_files\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0eb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/train'\n",
    "test_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/test'\n",
    "val_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c080c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(source_path, destination_path, titles):\n",
    "    for title in titles:\n",
    "        source_file = os.path.join(data_directory, title)\n",
    "        destination_file = os.path.join(destination_path, title)\n",
    "        shutil.copy(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b04cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_directory = \"/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/img_resized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490e14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#already done\n",
    "#copy_files(data_directory, train_path, train_ids)\n",
    "#copy_files(data_directory, val_path, val_ids)\n",
    "#copy_files(data_directory, test_path, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f78605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134823"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_image_files(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cdba8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/MMHS150K_GT.json'\n",
    "\n",
    "# Open the JSON file for reading\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f737fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.reset_index()\n",
    "newColumns = {\"index\": \"id\"}\n",
    "df = df.rename(columns=newColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5855206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 for nothate, #1 for hate\n",
    "def labels_to_binary(labels):\n",
    "    if sum(labels) <= 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c289aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61547"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Hate(1)_vs_NotHate(0)\"] = df[\"labels\"].apply(labels_to_binary)\n",
    "sum(df[\"Hate(1)_vs_NotHate(0)\"]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4d239c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nothate_ids = df[df[\"Hate(1)_vs_NotHate(0)\"]==0][\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9961e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_ids = df[df[\"Hate(1)_vs_NotHate(0)\"]==1][\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35b65bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nothate_ids = [x + '.jpg' for x in nothate_ids]\n",
    "hate_ids = [x + '.jpg' for x in hate_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac087cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hate_train_ids = []\n",
    "hate_val_ids = []\n",
    "hate_test_ids = []\n",
    "for id_ in hate_ids:\n",
    "    if id_ in train_ids:\n",
    "        hate_train_ids.append(id_)\n",
    "    elif id_ in test_ids:\n",
    "        hate_test_ids.append(id_)\n",
    "    else:\n",
    "        hate_val_ids.append(id_)\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c42416cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"nothate_train_ids = []\n",
    "nothate_val_ids = []\n",
    "nothate_test_ids = []\n",
    "for id_ in nothate_ids:\n",
    "    if id_ in train_ids:\n",
    "        nothate_train_ids.append(id_)\n",
    "    elif id_ in test_ids:\n",
    "        nothate_test_ids.append(id_)\n",
    "    else:\n",
    "        nothate_val_ids.append(id_)\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "598f1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project'\n",
    "\n",
    "# Define the image size based on the pre-trained model's requirements\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create an ImageDataGenerator for preprocessing images\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2db29051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134823 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators for training, validation, and test sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path, 'train'),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Assuming you have multiple classes\n",
    "    shuffle=False  # Important: Set shuffle to False for feature extraction\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path, 'valid'),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path, 'test'),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24d90e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Local path to save the weights file\n",
    "local_weights_path = '/Users/raghavraahul/Downloads/'\n",
    "\n",
    "# Download and save the weights\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.save_weights(local_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e63a2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model using the local weights file\n",
    "base_model = MobileNetV2(weights=local_weights_path, include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04750c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4214/4214 [==============================] - 3616s 858ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features from images using the pre-trained model\n",
    "train_features = base_model.predict(train_generator, steps=len(train_generator))\n",
    "validation_features = base_model.predict(validation_generator, steps=len(validation_generator))\n",
    "test_features = base_model.predict(test_generator, steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the features\n",
    "train_features = np.reshape(train_features, (len(train_generator.classes), -1))\n",
    "validation_features = np.reshape(validation_features, (len(validation_generator.classes), -1))\n",
    "test_features = np.reshape(test_features, (len(test_generator.classes), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cabdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save for later use to train custom model\n",
    "np.save('imagenet_train_features.npy', train_features)\n",
    "np.save('imagenet_validation_features.npy', validation_features)\n",
    "np.save('imagenet_test_features.npy', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load the extracted features\n",
    "train_features = np.load('imagenet_train_features.npy')\n",
    "validation_features = np.load('imagenet_validation_features.npy')\n",
    "test_features = np.load('imagenet_test_features.npy')\n",
    "\n",
    "# Load the corresponding labels for training\n",
    "train_labels = train_generator.classes\n",
    "validation_labels = validation_generator.classes\n",
    "test_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the custom model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=train_features.shape[1]))\n",
    "model.add(Dense(128, activation='relu', input_dim=train_features.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be267580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the extracted features\n",
    "history = model.fit(train_features, train_labels, \n",
    "                    epochs=10, \n",
    "                    batch_size=32,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c9193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1234342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38506b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24c6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531526c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649d87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4619967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96c14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa03373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2795e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d133851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c04ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2cba5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e865e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b754af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2950ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574158f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c6324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ce1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
